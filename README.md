# WebRAG: AI-Powered Web Knowledge Retrieval & QA ğŸš€  

An AI-powered retrieval-augmented generation (RAG) system that extracts information from webpages, processes it using a vector database, and generates intelligent responses via a Large Language Model (LLM).  

## ğŸ“Œ Features  
- **ğŸ”— Web Scraping**: Extracts text from web pages using BeautifulSoup and requests.  
- **ğŸ“‚ Text Processing**: Cleans and chunks text for vector storage.  
- **ğŸ” Hybrid Retrieval**: Combines keyword-based (BM25) and dense retrieval (FAISS/Pinecone).  
- **ğŸ¤– LLM Integration**: Uses OpenAI/GPT API for intelligent response generation.  
- **âš¡ Fast API Service**: Deploys as an API with FastAPI for easy integration.  
- **ğŸ“¦ Dockerized Deployment**: Ready for cloud deployment (AWS/GCP).  

---

## ğŸ“‚ Project Structure  

```bash
WebRAG/
â”‚â”€â”€ data/                 # Store scraped web data (optional)
â”‚â”€â”€ embeddings/           # Store FAISS/Pinecone vectors
â”‚â”€â”€ models/               # Fine-tuned models (if applicable)
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py        # Web scraping module
â”‚   â”œâ”€â”€ preprocess.py     # Text cleaning and chunking
â”‚   â”œâ”€â”€ embedder.py       # Sentence embedding (e.g., MiniLM, Ada-002)
â”‚   â”œâ”€â”€ retriever.py      # Hybrid retrieval (BM25 + FAISS)
â”‚   â”œâ”€â”€ generator.py      # LLM-based response generation
â”‚   â”œâ”€â”€ api.py            # FastAPI service
â”‚â”€â”€ notebooks/            # Jupyter notebooks for testing
â”‚â”€â”€ docker/               # Docker deployment files
â”‚â”€â”€ requirements.txt      # Dependencies
â”‚â”€â”€ README.md             # Project Documentation
